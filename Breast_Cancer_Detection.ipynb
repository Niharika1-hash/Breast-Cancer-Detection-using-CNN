{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_Cancer_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niharika1-hash/Breast-Cancer-Detection-using-Machine-Learning/blob/main/Breast_Cancer_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-B9cYvt03_07"
      },
      "source": [
        "# **Project : Breast Cancer Prediction**\n",
        "***By*** \n",
        "\n",
        "***Niharika Poddar : 1RN18CS068***\n",
        "\n",
        "***Pooja R : 1RN18CS071***\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwKPDDQeGfeE"
      },
      "source": [
        "## **Problem Statement**\n",
        "\n",
        "Predict whether a patient has Breast Cancer or not, given a labelled dataset of Breast Cancer Tumour attributes for training using various ML techniques\n",
        "\n",
        "\n",
        "**Training and Test Dataset source** : https://www.kaggle.com/uciml/breast-cancer-wisconsin-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nR--oEXecXNB"
      },
      "source": [
        "## **Downloading Dataset from Kaggle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pMzaj02ceB4",
        "outputId": "d9fc6253-5bc9-4271-f743-b3f2a28cfd33"
      },
      "source": [
        "! pip install kaggle"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw7ujJXSci1b"
      },
      "source": [
        "! mkdir ~/.kaggle"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arzrMvdEcobK"
      },
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42bmejypcrwK"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BbX0E0Tcu_c",
        "outputId": "e2b86e05-254a-4412-a118-0a9036080e26"
      },
      "source": [
        "! kaggle datasets download -d uciml/breast-cancer-wisconsin-data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "breast-cancer-wisconsin-data.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK1_fex3dqI0",
        "outputId": "76a269bb-4ef5-426b-b1ba-d7c00a289950"
      },
      "source": [
        "! unzip breast-cancer-wisconsin-data.zip"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  breast-cancer-wisconsin-data.zip\n",
            "  inflating: data.csv                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlEswgbqGnB1"
      },
      "source": [
        "## **Dataset Analysis and Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az-jgEcTEY6l"
      },
      "source": [
        "\n",
        " > ### Import libraries\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZO4kXB93AQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f10e57-1f1b-4f7a-be77-482293c06a57"
      },
      "source": [
        "!pip install sklearn\n",
        "#importing libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy\n",
        "import seaborn as sns\n",
        "import sklearn\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxjmpgT2oGJc",
        "outputId": "f7a20194-a32a-41b6-d915-2d7fdeb98b16"
      },
      "source": [
        "!ls\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "breast-cancer-wisconsin-data.zip  data.csv  kaggle.json  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cu_WvFQHinr"
      },
      "source": [
        "\n",
        "\n",
        "> ### Dataset Description\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jy-vkgoNeme-"
      },
      "source": [
        "df = pd.read_csv(\"data.csv\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4908z9Rf7yq8"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvQaE8CO60c2"
      },
      "source": [
        "#data preprocessing\n",
        "df.info() #to find the number of null values in each column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-jCnmuR70Tx"
      },
      "source": [
        "#remove column no. 32\n",
        "df = df.dropna(axis=1)\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPw9BxqK8CyX"
      },
      "source": [
        "df.describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wLc5zwp88xE"
      },
      "source": [
        "#count of malignant and benign instances\n",
        "df['diagnosis'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-tHjZqg90Lg"
      },
      "source": [
        "sns.countplot(df['diagnosis'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4xuXeCaHqll"
      },
      "source": [
        "\n",
        "\n",
        "> ### Relabelling Target Values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDAhMTBq-OhF"
      },
      "source": [
        "#encoded label M as 1 and B as 0\n",
        "\n",
        "labelencoder_Y = LabelEncoder()\n",
        "df.iloc[:,1] = labelencoder_Y.fit_transform(df.iloc[:,1].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzni0jc0I869"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSSz9eAGIZJR"
      },
      "source": [
        "\n",
        "> ### Data Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tjyoREuOmpJ"
      },
      "source": [
        "sns.pairplot(df.iloc[:,1:5],hue=\"diagnosis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1mSVnYBO_Jh"
      },
      "source": [
        "#get the correlation\n",
        "df.iloc[:,1:32].corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgsCCWvHTtaw"
      },
      "source": [
        "#visualization of correlation\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(df.iloc[:,1:10].corr(),annot=True,fmt=\".0%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNXzU7P7I7MT"
      },
      "source": [
        "> ### Splitting Data into Training Dataset and Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV6PGmwqVYeH"
      },
      "source": [
        "#split dataset into dependent(x) and independent(y) variables\n",
        "x= df.iloc[:,2:31].values\n",
        "y= df.iloc[:,1].values\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dz2OtH0V6XM"
      },
      "source": [
        "#split dataset into training and testing dataset\n",
        "\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20,random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP4TjqM3WeU0"
      },
      "source": [
        "#feature scaling\n",
        "\n",
        "x_train = StandardScaler().fit_transform(x_train)\n",
        "x_test = StandardScaler().fit_transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WCQ0f3CFxS-"
      },
      "source": [
        "## **Technique 1: Classifiers**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1R5JZZBKgRh"
      },
      "source": [
        "> ### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPAt88LpN2KU"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hHOWK3qg2Hk"
      },
      "source": [
        "> ### Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nZkl-tpWjZ6"
      },
      "source": [
        "\n",
        "def logistic_regression(x_train,y_train):\n",
        "  log = LogisticRegression(random_state = 0)\n",
        "  log.fit(x_train,y_train)\n",
        "  return log\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pqzJtMYhUwP"
      },
      "source": [
        "> ### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO56WsdohMCw"
      },
      "source": [
        "def decision_tree(x_train,y_train):\n",
        "  tree = DecisionTreeClassifier(random_state = 0, criterion = \"entropy\")\n",
        "  tree.fit(x_train,y_train)\n",
        "  return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLVenvcPkIWU"
      },
      "source": [
        "> ### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLNw7qBkAAQ"
      },
      "source": [
        "def random_forest(x_train,y_train):\n",
        "  forest = RandomForestClassifier(random_state = 0, criterion = \"entropy\",n_estimators = 10)\n",
        "  forest.fit(x_train,y_train)\n",
        "  return forest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTHXfAGAf1Xk"
      },
      "source": [
        "model=[]\n",
        "model.append(logistic_regression(x_train,y_train))\n",
        "model.append(decision_tree(x_train,y_train))\n",
        "model.append(random_forest(x_train,y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d4AR_kgOJmv"
      },
      "source": [
        "> ### Accuracy Report\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDUEm4cLgLKh"
      },
      "source": [
        "#testing the model/result\n",
        "for i in range(len(model)):\n",
        "  print('\\n')\n",
        "  print(\"Model\",i)\n",
        "  print(classification_report(y_test,model[i].predict(x_test)))\n",
        "  print('Accuracy : ',accuracy_score(y_test,model[i].predict(x_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHWdi_-vOUGH"
      },
      "source": [
        "> ### Prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYqrzUIhiLt"
      },
      "source": [
        "#prediction of random forest\n",
        "pred = model[2].predict(x_test)\n",
        "print('Predicted Values:\\n',pred)\n",
        "print('Actual Values:\\n',y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dgV2JwBmw7O"
      },
      "source": [
        "## **Technique 2: Feature Selection with Random Forest**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ux6Sv1MO7ei"
      },
      "source": [
        "> ### Splitting Data into Training Dataset and Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tkI7aU9O5eV"
      },
      "source": [
        "# split data train 70 % and test 30, this time with x and not x_1 in order to have all the features %\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGPQGtPiPODo"
      },
      "source": [
        "> ### Creation of RFE object and Ranking each Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2c4auSAm2lQ"
      },
      "source": [
        "\n",
        "# Create the RFE object and rank each feature\n",
        "clf_rf_2 = RandomForestClassifier(random_state=43)      \n",
        "rfe = RFE(estimator=clf_rf_2, n_features_to_select=16, step=1)\n",
        "rfe = rfe.fit(x_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIRcugPDPihJ"
      },
      "source": [
        "> ### Accuracy Report and Confusion Matrix\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wofbljpRPgaq"
      },
      "source": [
        "recall = recall_score(y_test,rfe.predict(x_test))\n",
        "print('Recall is: ', recall)\n",
        "accuracy = accuracy_score(y_test,rfe.predict(x_test))\n",
        "print('Accuracy is: ', accuracy)\n",
        "f1 = f1_score(y_test,rfe.predict(x_test))\n",
        "print('F1 score is: ', f1)\n",
        "cm = confusion_matrix(y_test,rfe.predict(x_test))\n",
        "sns.heatmap(cm,annot=True,fmt=\"d\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9kghRHHFoOf"
      },
      "source": [
        "## **Technique 3: CNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la0uu0dVP9tf"
      },
      "source": [
        "> ### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXpArd5zK_wW"
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qqm60F9-Fm5U"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y31XzaBYGSRM"
      },
      "source": [
        "from sklearn import datasets, metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Oegc1XQQMc8"
      },
      "source": [
        "> ### Splitting Data into Training Dataset and Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkNZun42QIfJ"
      },
      "source": [
        "# split data train 70 % and test 30, this time with x and not x_1 in order to have all the features %\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-OpOFpBQOJX"
      },
      "source": [
        "> ### Scaling the Training and Testing Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J9YCMh-GX_F"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
        "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GciyhzSuQXqm"
      },
      "source": [
        "> ### Training the CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsaD7Gn1GX7y"
      },
      "source": [
        "epochs = 300\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Conv1D(filters=32,kernel_size = 2,activation = 'relu',input_shape=(29,1)))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "cnn_model.add(Conv1D(filters=32,kernel_size = 2,activation = 'relu'))\n",
        "cnn_model.add(BatchNormalization())\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "cnn_model.add(Flatten())\n",
        "cnn_model.add(Dense(64, activation = 'relu'))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "cnn_model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRU2Td_YQfO2"
      },
      "source": [
        "> ### Training Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzgms6UlH2ho"
      },
      "source": [
        "cnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiRc2dXnH8sm"
      },
      "source": [
        "cnn_model.compile(optimizer = Adam(lr = 0.00005), loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do2w3AhaIqaX"
      },
      "source": [
        "def plot_learningCurve(history,epoch):\n",
        "  epoch_range = range(1,epoch+1)\n",
        "  plt.plot(epoch_range,history.history['accuracy'])\n",
        "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
        "  plt.title('Model accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train','Val'], loc = 'upper left')\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(epoch_range,history.history['loss'])\n",
        "  plt.plot(epoch_range,history.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train','Val'], loc = 'upper left')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekl9blzDH-zO"
      },
      "source": [
        "history = cnn_model.fit(x_train,y_train,epochs = epochs, validation_data=(x_test,y_test), verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYSU26HTQmsN"
      },
      "source": [
        "> ### Learning Curve Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qCy7ksgJN_L"
      },
      "source": [
        "plot_learningCurve(history,epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNj912khsDBQ"
      },
      "source": [
        "## **Final Output Comparison**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlJdF2rhNqAg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}